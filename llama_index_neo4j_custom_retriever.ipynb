{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tomasonjo/blogs/blob/master/llm/llama_index_neo4j_custom_retriever.ipynb\n",
    "https://www.llamaindex.ai/blog/customizing-property-graph-index-in-llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet llama-index\n",
    "%pip install --quiet llama-index-graph-stores-neo4j\n",
    "%pip install --quiet llama-index-program-openai\n",
    "%pip install --quiet llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
    "\n",
    "username=\"neo4j\"\n",
    "password=\"spoon-ralph-point-topic-armani-9842\"\n",
    "url=\"bolt://localhost:7687\"\n",
    "\n",
    "graph_store = Neo4jPGStore(\n",
    "    username=username,\n",
    "    password=password,\n",
    "    url=url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document\n",
    "\n",
    "news = pd.read_csv(\n",
    "  \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\")\n",
    "documents = [Document(text=f\"{row['title']}: {row['text']}\") for i, row in news.iterrows()]\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "entities = Literal[\"PERSON\", \"LOCATION\", \"ORGANIZATION\", \"PRODUCT\", \"EVENT\"]\n",
    "relations = Literal[\n",
    "    \"SUPPLIER_OF\",\n",
    "    \"COMPETITOR\",\n",
    "    \"PARTNERSHIP\",\n",
    "    \"ACQUISITION\",\n",
    "    \"WORKS_AT\",\n",
    "    \"SUBSIDIARY\",\n",
    "    \"BOARD_MEMBER\",\n",
    "    \"CEO\",\n",
    "    \"PROVIDES\",\n",
    "    \"HAS_EVENT\",\n",
    "    \"IN_LOCATION\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which entities can have which relations\n",
    "validation_schema = {\n",
    "    \"Person\": [\"WORKS_AT\", \"BOARD_MEMBER\", \"CEO\", \"HAS_EVENT\"],\n",
    "    \"Organization\": [\n",
    "        \"SUPPLIER_OF\",\n",
    "        \"COMPETITOR\",\n",
    "        \"PARTNERSHIP\",\n",
    "        \"ACQUISITION\",\n",
    "        \"WORKS_AT\",\n",
    "        \"SUBSIDIARY\",\n",
    "        \"BOARD_MEMBER\",\n",
    "        \"CEO\",\n",
    "        \"PROVIDES\",\n",
    "        \"HAS_EVENT\",\n",
    "        \"IN_LOCATION\",\n",
    "    ],\n",
    "    \"Product\": [\"PROVIDES\"],\n",
    "    \"Event\": [\"HAS_EVENT\", \"IN_LOCATION\"],\n",
    "    \"Location\": [\"HAPPENED_AT\", \"IN_LOCATION\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    kg_validation_schema=validation_schema,\n",
    "    # if false, allows for values outside of the schema\n",
    "    # useful for using the schema as a suggestion\n",
    "    strict=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "NUMBER_OF_ARTICLES = 150\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents[:NUMBER_OF_ARTICLES],\n",
    "    kg_extractors=[kg_extractor],\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store.structured_query(\"\"\"\n",
    "CREATE VECTOR INDEX entity IF NOT EXISTS\n",
    "FOR (m:`__Entity__`)\n",
    "ON m.embedding\n",
    "OPTIONS {indexConfig: {\n",
    " `vector.dimensions`: 1536,\n",
    " `vector.similarity_function`: 'cosine'\n",
    "}}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for inspection\n",
    "similarity_threshold = 0.9\n",
    "word_edit_distance = 5\n",
    "data = graph_store.structured_query(\"\"\"\n",
    "MATCH (e:__Entity__)\n",
    "CALL {\n",
    "  WITH e\n",
    "  CALL db.index.vector.queryNodes('entity', 10, e.embedding)\n",
    "  YIELD node, score\n",
    "  WITH node, score\n",
    "  WHERE score > toFLoat($cutoff)\n",
    "      AND (toLower(node.name) CONTAINS toLower(e.name) OR toLower(e.name) CONTAINS toLower(node.name)\n",
    "           OR apoc.text.distance(toLower(node.name), toLower(e.name)) < $distance)\n",
    "      AND labels(e) = labels(node)\n",
    "  WITH node, score\n",
    "  ORDER BY node.name\n",
    "  RETURN collect(node) AS nodes\n",
    "}\n",
    "WITH distinct nodes\n",
    "WHERE size(nodes) > 1\n",
    "WITH collect([n in nodes | n.name]) AS results\n",
    "UNWIND range(0, size(results)-1, 1) as index\n",
    "WITH results, index, results[index] as result\n",
    "WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
    "        CASE WHEN index <> index2 AND\n",
    "            size(apoc.coll.intersection(acc, results[index2])) > 0\n",
    "            THEN apoc.coll.union(acc, results[index2])\n",
    "            ELSE acc\n",
    "        END\n",
    ")) as combinedResult\n",
    "WITH distinct(combinedResult) as combinedResult\n",
    "// extra filtering\n",
    "WITH collect(combinedResult) as allCombinedResults\n",
    "UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
    "WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
    "WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1)\n",
    "    WHERE x <> combinedResultIndex\n",
    "    AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
    ")\n",
    "RETURN combinedResult\n",
    "\"\"\", param_map={'cutoff': similarity_threshold, 'distance': word_edit_distance})\n",
    "data\n",
    "for row in data:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
